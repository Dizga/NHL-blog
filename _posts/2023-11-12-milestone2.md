---
layout: post
title: Milestone 2
---
## Ingénierie des caractéristiques 1


### 1.
{% include hist1.html %}

Entre 0 et 50 unités de distance du filet, il y a une augmentation significative du nombre de tirs. Cela suggère que les joueurs ont tendance à prendre des tirs plus fréquemment lorsqu'ils sont très proche du filet.

Entre 50 et 200 unités de distance du filet, le nombre de tirs diminue considérablement. Cela peut indiquer que les joueurs sont moins enclins à tenter des tirs lorsqu'ils sont très éloignés du filet. 

La fréquence des buts est plus élevée entre 0 et 40 unités de distance du filet. Cela pourrait signifier que les tirs effectués à des distances proches du filet ont une plus grande probabilité de se transformer en buts.
 
{% include hist2.html %}
Le nombre de tirs est très élevé lorsque l'angle est -40 et 40 atteignant jusqu'à 14000 tirs.  Ces angles correspondent probablement à des tirs plus directs vers le filet. Le nombre de trs pour des angles entre -100 et -50 et entre 50 et 100 semblent etre faible. Cela peut signifier que les joueurs évitent de tirer depuis des positions extrêmement latérales où il est plus difficile de viser avec précision et d'obtenir un bon angle d'attaque sur le filet.

![](/assets/images/hist3.png)
Pour les distances proches (0-50) :

Il y a un grand nombre de tirs qui ont été effectués à des distances relativement proches du filet.
Ces tirs sont répartis sur toute la plage des angles possibles, ce qui suggère que les joueurs tirent de ces distances à partir de diverses directions.

Pour les distances plus éloignées (50-100) :

Le nombre de tirs diminue considérablement par rapport à ceux à courte distance.
Les tirs à ces distances semblent être plus concentrés autour de l'angle -25 à 25 degrés.
Ces observations peuvent indiquer des stratégies de jeu différentes en fonction de la distance au filet. Les tirs de près semblent être moins ciblés en termes d'angle, tandis que les tirs de loin semblent être plus concentrés vers le centre du filet. 

### 2.

{% include shot-distance_proportions.html %}

Avant 80 ft, on peut voir que la proportion de buts est plus grande quand les tirs sont plus proches. Après 80 ft, la proportion de buts augmentes légèrement autour de 7%, cela peux s'expliquer par le fait que beaucoup des tirs lointains sont faits lorsque les filets adverses sont vides.

{% include shot-angle_proportions.html %}

On peut voir que la proportion de buts diminue lorsque l'angle de tir augmente.


### 3.
{% include goals-empty-net.html %}

On peut voir qu'à partir d'une certaine distance (environ 70 ft) la plupart des buts sont marqués quand les filets sont vides. Ce qui semble logique puisque qu'un tire très éloigné sera facile à arrêter par le gardien.

Pour trouver des événements qui ont des caractéristiques incorrectes, on peut faire une recherche sur les données pour les buts marqué à plus d'une certaine distance (ex: 165 ft) quand le gardien adverse était dans ces filets:

```
df.loc[(df.Shot_distance > 165) &
       (df.Empty_net == False) &
       (df.Goal == True)]
```

Un exemple d'événements incorrect est le but fait par Ryan Donato contre Detroit, on peut voir sur la [video](https://www.nhl.com/gamecenter/det-vs-min/2020/02/27/2019020989) du match que Ryan Donato n'était pas à 165 ft des buts:

| Year | Game_id | Shooter     | Shot distance (ft) |
|------|---------|-------------|--------------------|
| 2019 |     989 | Ryan Donato |                165 |

{% include video_goal.html %}
[](https://duckduckgo.com)

## Modèles de base
### 1.

Lors de l'entraînement du modèle de régression logistique, nous avons obtenu une précision (accuracy) impressionnante de 90%! À première vue, ce résultat pourrait suggérer que le modèle performe bien. Cependant, un regard sur les prédictions révèle une limitation majeure : le modèle prédit systématiquement que chaque tir n'est pas un but. Cela lui permet d'atteindre une précision élevée puisque seulement 10% des tirs sont effectivement des buts. Ainsi, en prédisant constamment `Non but`, le modèle parvient à obtenir une très bonne précision.

Cela pose un problème significatif lorsqu'on évalue la capacité du modèle à identifier correctement les buts réels. En effet, en testant sa valeur de rappel (recall), qui mesure sa capacité à détecter tous les cas positifs réels (dans ce cas, les buts), nous constatons que le modèle obtient un taux de 0%. Cela signifie que le modèle échoue complètement à identifier les tirs qui sont effectivement des buts.

### 3.
Les résultats révèlent une courbe ROC de 0,7, indiquant une performance acceptable mais pas exceptionnelle du modèle pour distinguer les deux étiquettes. Néanmoins, il surpasse significativement le cas naïf (courbe ROC = 0,5). La courbe d'étalonnage, représentée par trois points formant une ligne avec une pente légèrement supérieure à 1, suggère une tendance du modèle à manquer de confiance dans ses prédictions. Les analyses du taux d'objectifs et de la proportion cumulée d'objectifs confortent davantage cette observation, montrant que 60 % des probabilités présentent une variation linéaire décroissante avec le taux d'objectifs, tandis que les 40 % restants ne présentent aucune variation significative. Remédier à ce manque de confiance pourrait être un domaine clé pour optimiser et améliorer le calibrage du modèle.

![](/assets/images/output1.png)

![](/assets/images/output2.1.png)
![](/assets/images/output2.2.png)

Les résultats révèlent une courbe ROC de 0,7, indiquant une performance acceptable mais pas exceptionnelle du modèle pour distinguer les deux étiquettes. Néanmoins, il surpasse significativement le cas naïf (courbe ROC = 0,5). La courbe d'étalonnage, représentée par trois points formant une ligne avec une pente légèrement supérieure à 1, suggère une tendance du modèle à manquer de confiance dans ses prédictions. Les analyses du taux d'objectifs et de la proportion cumulée d'objectifs confortent davantage cette observation, montrant que 60 % des probabilités présentent une variation linéaire décroissante avec le taux d'objectifs, tandis que les 40 % restants ne présentent aucune variation significative. Remédier à ce manque de confiance pourrait être un domaine clé pour optimiser et améliorer le calibrage du modèle.
## Ingénierie des caractéristiques 2

Ci-dessous, la liste et la description des caractéristiques créées. Le dataframe de ces caractéristiques appliquées au match Winnipeg vs Washington du 12 mars 2018 peut être trouvé [ici](https://www.comet.com/imenjaoua/ift6758/7a4a681587224f438ef3d152572311b9?experiment-tab=panels&showOutliers=true&smoothing=0&viewId=TYI36Yxc9U0CJXWkAyg2Qil8s&xAxis=step). (A noté que les données sont presenté ici sans la mise à l'échelle, l'encodage et la gestion du débalancement.)

( Les caractéristiques refletant la situation de jeu de puissance sont `Players` et `Opp_Players`. )

| Colonne             | Description                                                                                                                               |
|---------------------|-------------------------------------------------------------------------------------------------------------------------------------------|
| Game id             | Le numero du jeu, representé par les quatres derniers chiffres de l'ID definie par statsapi.  e.g. pour "2016020146" le Game_id sera 146. |
| Game time           | Nombre de seconde passé depuis le debut du match, sans compter les arrets de jeux.                                                        |
| Period              | La periode de jeu.                                                                                                                        |
| Time                | Nombre de seconde passé depuis le debut de la periode, sans compter les arrets de jeux.                                                   |
| Team                | Tricode de l'equipe. e.g. MTL, TOR, etc                                                                                                   |
| Opp Team            | Tricode de l'equipe adverse. e.g. MTL, TOR, etc                                                                                           |
| X                   | Position du tir sur l'axe des X.                                                                                                          |
| Y                   | Position du tir sur l'axe des Y.                                                                                                          |
| Shooter             | Nom du tireur.                                                                                                                            |
| Goalie              | Nom du Gardien adverse.                                                                                                                   |
| Type                | Type de tir. e.g. Wrist, slap, etc                                                                                                        |
| Empty net           | Boolean définissant si le filet adverse est vide.                                                                                         |
| Previous event type | Nom de l'évènement précèdent.                                                                                                             |
| Previous x          | Position de l'évènement précèdent sur l'axe des X.                                                                                        |
| Previous y          | Position de l'évènement précèdent sur l'axe des Y.                                                                                        |
| Previous time since | Nombre de seconde passé depuis l'évènement précèdent.                                                                                     |
| Previous distance   | Distance depuis l'évènement précèdent.                                                                                                    |
| Speed               | La distance depuis l'événement précédent, divisée par le temps écoulé depuis l'événement précédent.                                       |
| Is rebound          | Boolean définissant si le tir est un rebond, si l'evenement precedent est un tir.                                                         |
| Time since powp     | Nombre de seconde écoulé depuis que l'équipe est en superiorité numérique (0 sinon)                                                       |
| Players             | Nombre de joueur de l'équipe sur la patinoire (sans compter le gardien)                                                                   |
| Opp players         | Nombre d'adversaire sur la patinoire (sans compter le gardien)                                                                            |
| X net               | Distance du tir depuis le but adverse sur l'axe des X.                                                                                    |
| Shot distance       | Distance du tir depuis le but adverse.                                                                                                    |
| Shot angle          | Angle du tir depuis le but adverse.                                                                                                       |
| Rebound angle       | Angle du tir depuis le tir precedent s'il s'agit d'un rebond.                                                                             |
| Year                | Année de la saison. e.g. pour la saison 2017-2018 Year sera 2017.                                                                         |
| Shooter ratio       | Moyenne mobile exponentiel (EMA) de la proportion de but du tireur, calculé sur les jeux prédédents.                                      |
| Goalie ratio        | Moyenne mobile exponentiel (EMA) de la proportion d'arret du gardien adverse, calculé sur les jeux prédédents.                            |
| Team goals          | Moyenne mobile exponentiel (EMA) du nombre de buts de l'équipe, calculé sur les jeux prédédents.                                          |
| Opp concedes        | Moyenne mobile exponentiel (EMA) du nombre de buts concédés par l'équipe adverse, calculé sur les jeux prédédents.                        |


Pour la mise à l'echelle, une simple standardisation à été faites.
Certaine caractéristiques catégorielles comme `Type` et `Previous event type` on été encodé par encodage moyen cible. D'autres, tels que (`Team`, `Opp Team`, etc.) on été encodé par encodage ordinal car d'autres caractéristiques (`Team goals`, `Opp concedes`, etc.) encode déjà leur relation avec le label. Le débalancement des données sera géré par les modèles, avec par exemple, l'attribut `scale_pos_weight` de XGBoost.


## Modèles avancés 
### 1. 
Dans cette expérience, nous avons entraîné un classificateur XGBoost en utilisant uniquement les caractéristiques de distance et d'angle sur le même ensemble de données. La configuration d'entraînement/validation a suivi une approche standard avec l'ensemble d'entraînement et l'ensemble de validation, sans ajustement des hyperparamètres.

Les résultats obtenus avec XGBoost sont illustré dans cette figure montrant une amélioration significative par rapport à la référence de régression logistique. La courbe ROC AUC obtenue avec XGBoost a démontré un meilleur résultat.

<!-- ![](/assets/images/xgboost_dist+angle.png) -->
![](/assets/images/xgd-distance-angle.png)


Lien vers cette [expérience](https://www.comet.com/imenjaoua/ift6758/f52d3fa5d94f49239d959e961ff4eee7?experiment-tab=panels&showOutliers=true&smoothing=0&viewId=awZLr6P6ZceD5nGLhvCSFIw6C&xAxis=wall).

### 2.
Pour sélectionner la combinaison optimale d'hyperparamètres pour notre modèle XGBoost, nous avons employé la méthode Grid Search couplée à la validation croisée. Les hyperparamètres que nous avons explorés comprennent la profondeur maximale de l'arbre (max_depth), le nombre d'arbres (n_estimators), le taux d'apprentissage (learning_rate) et le poids des échantillons positifs (scale_pos_weight). Pour évaluer les performances du modèle, nous avons utilisé les métriques de précision (accuracy) et l'aire sous la courbe ROC (Roc-AUC).

On peut voir dans ce graphique Comet quelques modèles avec leurs valeurs Accuracy vs AUC:
<iframe class='comet' width="600" height="400" frameborder="0" src="https://www.comet.com/embedded-panel/?chartId=BXOA5R&projectId=957b70ae0f3e4156baa257818f4bef1f&viewId=LnJn1Ifvth6VjL1Sco8tafMxl"></iframe>

<!-- Avant de faire cette expérience, nous avons utilisé Label Encoding sur les variables catégorielles telles que 'Team', 'OppTeam', 'Shooter', 'Goalie', 'Type', et 'Previous_event_type'. De plus, nous appliquons également l'encodage sur les variables booléennes 'Is_rebound', 'Empty_net', et 'Goal'. En se basant sur la matrice de corrélation, certaines colonnes jugées non pertinentes pour la prédiction, comme 'Time', 'Period', 'X', 'Y', 'Previous_x', 'Previous_y', et 'X_net', sont supprimées. -->
<!-- Dans cette expérience, nous avons entraîné XGBoost en utilisant toutes les caractériques. Les résultats obtenus sont significativement améliorés par rapport à la configuration précédente utilisant uniquement les caractéristiques d'angle et de distance. Ce qui soulignent l'importance des autres caractéristiques sur la performance du modèle.

Dans la prochaine phase de notre expérimentation, nous avons opté pour une approche plus approfondie en utilisant Grid Search pour déterminer la meilleure combinaison d'hyperparamètres pour notre modèle XGBoost. Les parametres qu'on a exploré sont la profondeur maximale de l'arbre (max_depth),le nombre d'arbres (n_estimators), le taux d'apprentissage (learning_rate), et le poids de l'échantillon positif (scale_pos_weight).
Nous avons utilisé la métrique AUC pour évaluer les performances du modèle. Les résultats obtenus ont été consignés pour chaque combinaison. -->
Cette figure montre la performance `Roc-AUC` pour quelques combinaisons d'hyperparamètres (non exhaustif, d'autres combinaisons ont été testées):

{% include hp-tuning.html %}

La meilleure combinaison obtenue est:

| max_depth | n_estimators | learning_rate | scale_pos_weight |
|-----------|--------------|---------------|------------------|
| 4         | 400          | 0.1           | 1.5              |

Avec ces hyperparamètres nous obtenons les figures:

![](/assets/images/xgboost_allfeatures.png)

Dans cette expérience, nous avons entraîné XGBoost en utilisant toutes les caractériques. Les résultats obtenus sont significativement améliorés par rapport à la configuration précédente utilisant uniquement les caractéristiques d'angle et de distance. Ce qui soulignent l'importance des autres caractéristiques sur la performance du modèle.

Lien vers cette [expérience](https://www.comet.com/imenjaoua/ift6758/dc4475f942d4498ba8e7edaceed0044e?experiment-tab=panels&showOutliers=true&smoothing=0&viewId=awZLr6P6ZceD5nGLhvCSFIw6C&xAxis=wall).

### 3.
Les stratégies de sélection de caractéristiques mises en œuvre ont combiné les analyses d'importance des caractéristiques via XGBoost, SHAP, et LASSO. En effet, cette figure représente la courbe d'importance des caractéristiques selon XGBoost, où la distance du tir (shot_distance), l'angle du tir, le temps écoulé depuis le dernier tir et la vitesse du joueur ont été des déterminants majeurs dans la réussite des tirs. 
![](/assets/images/importance_features.png)
L'application de la méthode SHAP a révélé que les caractéristiques les plus importantes pour la prédiction des résultats de tirs sont, dans l'ordre décroissant d'importance, la distance du tir (shot_distance), l'angle du tir (shot_angle), le temps écoulé depuis le dernier tir (previous_time_since) et le type. En effet, La distance et l'angle du tir et le temps écoulé depuis le dernier tirs'alignent avec les résultats obtenus par la méthode précèdente, soulignant leur importance cruciale. 
![](/assets/images/SHAP.png)
La sélection de caractéristiques par LASSO a montré des informations complémentaires aux résultats obtenus par XGBoost et SHAP. Les caractéristiques communes telles que 'Shot_distance' et 'Shot_angle' semblent jouer un rôle important dans la réussite des tirs, ce qui est cohérent avec les conclusions précédentes.

En particulier, la caractéristique 'Previous_time_since' identifiée par LASSO semble être un facteur important, s'alignant avec les résultats de SHAP. Cela prouve que le temps écoulé depuis le dernier tir est une variable significative pour prédire le succès des tirs.

 Après avoir appliqué ces méthode de sélection et les méthodes d'emballage (wrapper), nous avons identifié un ensemble de caractéristiques qui ont joué un rôle prometteur dans la réussite des tirs. Les caractéristiques sélectionnées sont: 
 
 * Game_id
 * Game_time
 * Type
 * Previous_event_type
 * Previous_time_since
 * Previous_distance
 * Speed
 * Time_since_powp 
 * Opp_players
 * X_net
 * Shot_distance
 * Shot_angle
 * Rebound_angle 
 * Shooter_ratio 
 * Goalie_ratio
 * Team_goals
 * Opp_concedes

 Les quatres figures des résultats de l'entrainement de xgboost sur ces caractériques sont illustrés dans la figure ci dessous.

 ![](/assets/images/xgboost_selectparams.png)

On peut voir que ce modèle est tres similaire au précèdent, on note cependant une amélioration sur la courbe de calibration.

Lien vers cette [expérience](https://www.comet.com/imenjaoua/ift6758/f889134123e1416d9e9058ab1ad73565?experiment-tab=panels&showOutliers=true&smoothing=0&viewId=awZLr6P6ZceD5nGLhvCSFIw6C&xAxis=wall). 


## Faites de votre mieux!

TODO

## Évaluer sur l'ensemble de test 

### 1.

![](/assets/images/all-regular.png)

Les classifieurs de régression logistique semblent présenter des performances similaires sur l'ensemble de test et sur l'ensemble de validation, ce qui est cohérent avec la nature de ces modèles. Étant donné leur simplicité (linéarité) et le fait qu'ils sont entraînés sur un nombre restreint de caractéristiques, leur complexité est réduite. Cela diminue le risque de sur-apprentissage tout en offrant une bonne généralisation. Cependant, cette simplicité peux aussi limiter leur capacité à capturer des relations plus complexes.

En revanche, les deux autres modèles, XGB et CatBoost, semblent avoir des performances differente sur l'ensemble de test, XGB par exemple, obtient un meilleur score Roc-AUC mais obtient une moins bonne courbe de calibration. Ces modèles sont intrinsèquement plus complexes et ont été entraînés sur un plus grand nombre de caractéristiques. Cette complexité accrue leur permet de mieux saisir les non-linéarités et les interactions subtiles dans les données, conduisant à de meilleures performances. Toutefois, cette complexité augmente également le risque de sur-apprentissage, ce qui peut expliquer une généralisation légèrement inférieure sur l'ensemble de test.

### 2.
![](/assets/images/all-playoffs.png)

<!-- Tout les modeles semble obtenir des resultat different sur les playoffs, meme les modeles de regression logistique qui devrait mieux generaliser, ce qui montre peut-etre un leger decalage dans les distribution des données match regulier vs playoffs. On peut s'éssayer à lister quelques facteurs qui differencie les matchs reguliers des matchs playoffs:

- Les joueurs peuvent se comporter différemment pendant les séries éliminatoires en raison des enjeux plus importants, ce qui peut changer la dynamique générale du jeu.
- Les équipes adoptent peut-etre des stratégies différentes pendant les séries éliminatoires.
- Les joueurs pourraient être plus fatigués pendant les playoffs.
- Les playoffs éliminent les équipes les plus faibles et le niveau de compétition est donc plus élevé.

Le modele entrainé avec Catboost semble moins bien generaliser que le modele entrainé avec XGBoost sur cette ensemble de test. -->

Tous les modèles semblent afficher des résultats diffèrent lorsqu'ils sont appliqués aux données des playoffs, y compris les modèles de régression logistique, qui sont théoriquement mieux adaptés pour généraliser. Cela peut indiquer une différence dans la distribution des données entre les matchs de saison régulière et ceux des playoffs. Plusieurs facteurs pourraient expliquer ces différences :

-Comportement des Joueurs : Les joueurs peuvent adopter des comportements différents durant les playoffs en raison des enjeux plus élevés. Cela peut modifier la dynamique du jeu.

-Stratégies d'Équipe : Il est possible que les équipes modifient leurs stratégies pendant les playoffs. Ces changements stratégiques peuvent ne pas être bien capturés par nos modèles, entraînés principalement sur des données de saison régulière.

-Fatigue des Joueurs : La fatigue accrue des joueurs pendant les playoffs pourrait affecter leurs performances.

-Niveau de Compétition : Avec l'élimination des équipes les moins performantes, le niveau de compétition pendant les playoffs est généralement plus élevé.

Concernant la performance des modèles spécifiques, le modèle entraîné avec CatBoost semble généraliser moins efficacement sur cet ensemble de données des playoffs comparé au modèle entraîné avec XGBoost. Cela suggère que XGBoost pourrait mieux gérer les variations ou les nuances spécifiques aux données des playoffs.
